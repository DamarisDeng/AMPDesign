{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis as PA\n",
    "from Bio import SeqIO, Seq\n",
    "from modlamp.descriptors import PeptideDescriptor, GlobalDescriptor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import re, math, pickle, platform, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:468: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:470: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:472: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:468: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:470: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:472: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/l1/3tjxrm457_3__m3s2nw9x2zm0000gn/T/ipykernel_40535/1253773279.py:468: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if n is 1:\n",
      "/var/folders/l1/3tjxrm457_3__m3s2nw9x2zm0000gn/T/ipykernel_40535/1253773279.py:470: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif n is 2:\n",
      "/var/folders/l1/3tjxrm457_3__m3s2nw9x2zm0000gn/T/ipykernel_40535/1253773279.py:472: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif n is 3:\n"
     ]
    }
   ],
   "source": [
    "# Miscellaneous\n",
    "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "             'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
    "             'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "n_gram statistics\n",
    "\"\"\"\n",
    "\n",
    "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H', \n",
    "            'I', 'K', 'L', 'M', 'N', 'P', 'Q', \n",
    "            'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "def get_aan_corpus(n=2):\n",
    "    '''\n",
    "    Get AA corpus of n_gram (e.g. Di, Tri, etc.)\n",
    "    Output: AA n_gram corpus ((e.g. Di:400, Tri:3000, etc.))\n",
    "    '''\n",
    "    n_corpus = []\n",
    "    if n <= 2:\n",
    "        for i in _AALetter:\n",
    "            for j in _AALetter:\n",
    "               n_corpus.append(\"{}{}\".format(i, j))\n",
    "        return n_corpus\n",
    "    for i in get_aan_corpus(n - 1):\n",
    "        for j in _AALetter:\n",
    "            n_corpus.append(\"{}{}\".format(i, j))\n",
    "    return n_corpus\n",
    "\n",
    "\n",
    "def get_ngram_counts(seq, n=2):\n",
    "    '''\n",
    "    Get n_gram statistics\n",
    "    Input: peptide sequence and n\n",
    "    Ouput: n_gram statistic (dictionary) {A.A Corp: Counts}\n",
    "    '''\n",
    "    # Get the name of ngram feature\n",
    "    if n == 2:\n",
    "        prefix = 'DPC'\n",
    "    elif n == 3:\n",
    "        prefix = 'TPC'\n",
    "    else:\n",
    "        prefix = '{}gram'.format(n)\n",
    "\n",
    "    ngrams = [seq[i: i + n] for i in range(len(seq) - n + 1)]\n",
    "    n_corpus = get_aan_corpus(n)\n",
    "    ngram_stat = {}\n",
    "    for aa_ng in n_corpus:\n",
    "        ngram_stat['{}|{}'.format(prefix, aa_ng)] = ngrams.count(aa_ng) / len(ngrams) * 100\n",
    "    return ngram_stat\n",
    "\n",
    "\n",
    "def minSequenceLength(fastas):\n",
    "    minLen = 10000\n",
    "    for i in fastas:\n",
    "        if minLen > len(i[1]):\n",
    "            minLen = len(i[1])\n",
    "    return minLen\n",
    "\n",
    "\n",
    "def minSequenceLengthWithNormalAA(fastas):\n",
    "    minLen = 10000\n",
    "    for i in fastas:\n",
    "        if minLen > len(re.sub('-', '', i[1])):\n",
    "            minLen = len(re.sub('-', '', i[1]))\n",
    "    return minLen\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    input.fasta:      the input protein sequence file in fasta format.\n",
    "    k_space:          the gap of two amino acids, integer, defaule: 5\n",
    "    output:           the encoding file, default: 'encodings.tsv'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generateGroupPairs(groupKey):\n",
    "    gPair = {}\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPair['CKSAAGP|'+key1+'.'+key2] = 0\n",
    "    return gPair\n",
    "\n",
    "\n",
    "def cksaagp(fastas, gap = 5, **kw):\n",
    "    if gap < 0:\n",
    "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    if minSequenceLength(fastas) < gap+2:\n",
    "        print('Error: all the sequence length should be greater than the (gap value) + 2 = ' + str(gap+2) + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    group = {'aliphatic': 'GAVLMI',\n",
    "             'aromatic': 'FYW',\n",
    "             'postivecharge': 'KRH',\n",
    "             'negativecharge': 'DE',\n",
    "             'uncharge': 'STCPNQ'}\n",
    "\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "\n",
    "    groupKey = group.keys()\n",
    "\n",
    "    index = {}\n",
    "    for key in groupKey:\n",
    "        for aa in group[key]:\n",
    "            index[aa] = key\n",
    "\n",
    "    gPairIndex = []\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPairIndex.append('CKSAAGP|'+key1+'.'+key2)\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for g in range(gap + 1):\n",
    "        for p in gPairIndex:\n",
    "            header.append(p+'.gap'+str(g))\n",
    "    encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        for g in range(gap + 1):\n",
    "            gPair = generateGroupPairs(groupKey)\n",
    "            sum = 0\n",
    "            for p1 in range(len(sequence)):\n",
    "                p2 = p1 + g + 1\n",
    "                if p2 < len(sequence) and sequence[p1] in AA and sequence[p2] in AA:\n",
    "                    gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] = gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] + 1\n",
    "                    sum = sum + 1\n",
    "\n",
    "            if sum == 0:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(0)\n",
    "            else:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(gPair[gp] / sum)\n",
    "\n",
    "        encodings.append(code)\n",
    "\n",
    "    return encodings\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    input.fasta:      the input protein sequence file in fasta format.\n",
    "    lambda:           the lambda value, integer, defaule: 30\n",
    "    output:           the encoding file, default: 'encodings.tsv'\n",
    "\"\"\"\n",
    "\n",
    "def Rvalue(aa1, aa2, AADict, Matrix):\n",
    "    return sum([(Matrix[i][AADict[aa1]] - Matrix[i][AADict[aa2]]) ** 2 for i in range(len(Matrix))]) / len(Matrix)\n",
    "\n",
    "\n",
    "def paac(fastas, lambdaValue=30, w=0.05, **kw):\n",
    "    if minSequenceLengthWithNormalAA(fastas) < lambdaValue + 1:\n",
    "        print('Error: all the sequence length should be larger than the lambdaValue+1: ' + str(lambdaValue + 1) + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    dataFile = re.sub('codes$', '', os.path.split(os.path.realpath('__file__'))[0]) + r'\\data\\PAAC.txt' if platform.system() == 'Windows' else re.sub('codes$', '', os.path.split(os.path.realpath('__file__'))[0]) + '/data/PAAC.txt'\n",
    "    with open(dataFile) as f:\n",
    "        records = f.readlines()\n",
    "    AA = ''.join(records[0].rstrip().split()[1:])\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    AAProperty = []\n",
    "    AAPropertyNames = []\n",
    "    for i in range(1, len(records)):\n",
    "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
    "        AAProperty.append([float(j) for j in array[1:]])\n",
    "        AAPropertyNames.append(array[0])\n",
    "\n",
    "    AAProperty1 = []\n",
    "    for i in AAProperty:\n",
    "        meanI = sum(i) / 20\n",
    "        fenmu = math.sqrt(sum([(j-meanI)**2 for j in i])/20)\n",
    "        AAProperty1.append([(j-meanI)/fenmu for j in i])\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for aa in AA:\n",
    "        header.append('PAAC|' + aa)\n",
    "    for n in range(1, lambdaValue + 1):\n",
    "        header.append('PAAC|lambda' + str(n))\n",
    "    encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        theta = []\n",
    "        for n in range(1, lambdaValue + 1):\n",
    "            theta.append(\n",
    "                sum([Rvalue(sequence[j], sequence[j + n], AADict, AAProperty1) for j in range(len(sequence) - n)]) / (len(sequence) - n))\n",
    "        myDict = {}\n",
    "        for aa in AA:\n",
    "            myDict[aa] = sequence.count(aa)\n",
    "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
    "        code = code + [(w * j) / (1 + w * sum(theta)) for j in theta]\n",
    "        encodings.append(code)\n",
    "    return encodings\n",
    "\n",
    "\n",
    "def GAAC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphatic': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharge': 'KRH',\n",
    "\t\t'negativecharge': 'DE',\n",
    "\t\t'uncharge': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#']\n",
    "\tfor key in groupKey:\n",
    "\t\theader.append(\"GAAC|\"+key)\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\t\tcode = [name]\n",
    "\t\tcount = Counter(sequence)\n",
    "\t\tmyDict = {}\n",
    "\t\tfor key in groupKey:\n",
    "\t\t\tfor aa in group[key]:\n",
    "\t\t\t\tmyDict[key] = myDict.get(key, 0) + count[aa]\n",
    "\n",
    "\t\tfor key in groupKey:\n",
    "\t\t\tcode.append(myDict[key]/len(sequence))\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "\n",
    "def GDPC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphaticr': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharger': 'KRH',\n",
    "\t\t'negativecharger': 'DE',\n",
    "\t\t'uncharger': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\tbaseNum = len(groupKey)\n",
    "\tdipeptide = [g1+'.'+g2 for g1 in groupKey for g2 in groupKey]\n",
    "\n",
    "\tindex = {}\n",
    "\tfor key in groupKey:\n",
    "\t\tfor aa in group[key]:\n",
    "\t\t\tindex[aa] = key\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#'] + ['GDPC|'+dipname for dipname in dipeptide]\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\n",
    "\t\tcode = [name]\n",
    "\t\tmyDict = {}\n",
    "\t\tfor t in dipeptide:\n",
    "\t\t\tmyDict[t] = 0\n",
    "\n",
    "\t\tsum = 0\n",
    "\t\tfor j in range(len(sequence) - 2 + 1):\n",
    "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]] + 1\n",
    "\t\t\tsum = sum +1\n",
    "\n",
    "\t\tif sum == 0:\n",
    "\t\t\tfor t in dipeptide:\n",
    "\t\t\t\tcode.append(0)\n",
    "\t\telse:\n",
    "\t\t\tfor t in dipeptide:\n",
    "\t\t\t\tcode.append(myDict[t]/sum)\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "\n",
    "def GTPC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphaticr': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharger': 'KRH',\n",
    "\t\t'negativecharger': 'DE',\n",
    "\t\t'uncharger': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\tbaseNum = len(groupKey)\n",
    "\ttriple = [g1+'.'+g2+'.'+g3 for g1 in groupKey for g2 in groupKey for g3 in groupKey]\n",
    "\n",
    "\tindex = {}\n",
    "\tfor key in groupKey:\n",
    "\t\tfor aa in group[key]:\n",
    "\t\t\tindex[aa] = key\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#'] + ['GTPC|'+tname for tname in triple]\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\n",
    "\t\tcode = [name]\n",
    "\t\tmyDict = {}\n",
    "\t\tfor t in triple:\n",
    "\t\t\tmyDict[t] = 0\n",
    "\n",
    "\t\tsum = 0\n",
    "\t\tfor j in range(len(sequence) - 3 + 1):\n",
    "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] + 1\n",
    "\t\t\tsum = sum +1\n",
    "\n",
    "\t\tif sum == 0:\n",
    "\t\t\tfor t in triple:\n",
    "\t\t\t\tcode.append(0)\n",
    "\t\telse:\n",
    "\t\t\tfor t in triple:\n",
    "\t\t\t\tcode.append(myDict[t]/sum)\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "'''\n",
    "Insert Iso_electric Point and net_charge(neutral) feature to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., iep, net_charge}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_phycs(seq_df):\n",
    "    seq_df = seq_df.copy()\n",
    "    #  Function for compute Isoelectric Point or net_charge of peptide\n",
    "    def get_ieq_nc(seq, is_iep=True):\n",
    "        protparam = PA(seq)\n",
    "        return protparam.isoelectric_point() if is_iep else protparam.charge_at_pH(7.0)\n",
    "\n",
    "    # Calculating IsoElectricPoints and NeutralCharge\n",
    "    data_size = seq_df.size\n",
    "    seq_df['PHYC|IEP'] = list(map(get_ieq_nc, seq_df['Sequence'], [True] * data_size))  # IsoElectricPoints\n",
    "    seq_df['PHYC|Net Charge'] = list(map(get_ieq_nc, seq_df['Sequence'], [False] * data_size))  # Charge(Neutral)\n",
    "\n",
    "    # Calculating hydrophobic moment (My assume all peptides are alpha-helix)\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'eisenberg')\n",
    "    descrpt.calculate_moment(window=1000, angle=100, modality='max')\n",
    "    seq_df['PHYC|Hydrophobic Moment'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating \"Hopp-Woods\" hydrophobicity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'hopp-woods')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Hydrophobicity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Energy of Transmembrane Propensity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'tm_tend')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Transmembrane Propensity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Aromaticity\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.aromaticity()\n",
    "    seq_df['PHYC|Aromacity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Levitt_alpha_helical Propensity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'levitt_alpha')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Alpha Helical Propensity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Aliphatic Index\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.aliphatic_index()\n",
    "    seq_df['PHYC|Aliphatic Index'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Boman Index\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.boman_index()\n",
    "    seq_df['PHYC|Boman Index'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "'''\n",
    "Insert Amino acid composition to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., AAC_Ax ... AAC_Yx}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_aac(seq_df):\n",
    "    seq_df = seq_df.copy()\n",
    "    # Compute AAC for peptide in specific A.A\n",
    "    def get_aac(seq, aa):\n",
    "        return seq.count(aa) / len(seq) * 100\n",
    "\n",
    "    # processing data_frame\n",
    "    data_size = seq_df.size\n",
    "    for ll in _AALetter:\n",
    "        seq_df['AAC|{}'.format(ll)] = list(map(get_aac, seq_df['Sequence'], [ll] * data_size))\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "'''\n",
    "Insert n_grams Descriptor to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., ngram_(1), .., ngram(20 ** n)}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_ngrams(seq_df, n=2):\n",
    "    seq_df = seq_df.copy()\n",
    "    data_size = seq_df.size\n",
    "\n",
    "    ngrams_df = list(map(get_ngram_counts, seq_df['Sequence'], [n] * data_size))\n",
    "    ngrams_df = pd.DataFrame(ngrams_df)  # Convert ngrams features to pd.DataFrame\n",
    "    seq_df = pd.concat([seq_df, ngrams_df], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert CKSAAGP Descriptor to the sequence data_frame\n",
    "(Composition of k-spaced amino acid pairs)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_cksaagp(seq_df, gap=2):\n",
    "    seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    encoding = cksaagp(fastas, gap=gap)\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert PAAC Descriptor to the sequence data_frame\n",
    "(Pseudo Amino Acid Composition)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_paac(seq_df, lamb=3, w=0.1):\n",
    "    seq_df = seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert Grouped n-gram Descriptor to the sequence data_frame\n",
    "(Pseudo Amino Acid Composition)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_gngram(seq_df, n=1):\n",
    "    seq_df = seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    # encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
    "    if n is 1:\n",
    "        encoding = GAAC(fastas)\n",
    "    elif n is 2:\n",
    "        encoding = GDPC(fastas)\n",
    "    elif n is 3:\n",
    "        encoding = GTPC(fastas)\n",
    "    else:\n",
    "        raise Warning(\"Invalid n-grams, no features added\")\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "def construct_features(seq_df, paaclamb=4, paacw=0.5):\n",
    "    \"\"\"\n",
    "    Construct Features for the AVPIden. We first investigated physiochemical feautres, AAC features, DiC features, \n",
    "    CKSAAGP features, PAAC features, and PHYC features.\n",
    "    Parameters are pre-set according to the sequence identities.\n",
    "    \"\"\"\n",
    "    seq_df = insert_aac(seq_df)\n",
    "    seq_df = insert_ngrams(seq_df, n=2)\n",
    "    seq_df = insert_cksaagp(seq_df, gap=3) # As the maximum motif length = 5.\n",
    "    seq_df = insert_paac(seq_df, lamb=paaclamb, w=paacw)\n",
    "    seq_df = insert_phycs(seq_df)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "def write_fasta(df, file_path, abbr_columns=None):\n",
    "    \"\"\"\n",
    "    Save dataframe to a .fasta file, the df should contain at least columns named \"Id\" and \"Sequence\"\n",
    "    \n",
    "    df: dataframe for saving .fasta\n",
    "    file_path: path(string) for saving the fasta file\n",
    "    abbr_columns: string columns for adding abbreviations. Multiple abbr are splited by '|'.\n",
    "    \"\"\"\n",
    "    Seqrecords = [SeqIO.SeqRecord(id=row['Id'], \n",
    "                              seq=Seq.Seq(row['Sequence']), \n",
    "                              description='|'.join(row[abbr_columns] if abbr_columns is not None else \"\")) \\\n",
    "             for idn, row in df.iterrows()]\n",
    "    with open(file_path, 'w+') as fhandle:\n",
    "        SeqIO.write(Seqrecords, fhandle, \"fasta-2line\")\n",
    "        print(\"Saved {:d} sequences.\".format(len(Seqrecords)))\n",
    "\n",
    "\n",
    "def read_fasta(fname):\n",
    "    '''\n",
    "    Read fasta file to dictionary\n",
    "    Input: path name of fasta\n",
    "    Output: dataframe of Peptide Seq {ID1: Seq1, ID2: Seq2,...}\n",
    "    '''\n",
    "    with open(fname, \"rU\") as f:\n",
    "        seq_dict = [(record.id, record.seq._data) for record in SeqIO.parse(f, \"fasta\")]\n",
    "    seq_df = pd.DataFrame(data=seq_dict, columns=[\"Id\", \"Sequence\"])\n",
    "    return seq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run extraction on sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAGMGFFGAR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAHCIQLGKR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAHCIVLHHN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAHCLAIGRK</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAHCLAIGRR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>MLSLIFLHRLKSMRKRLDRKLRLWHRKNYP</td>\n",
       "      <td>3446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>MLTAEEKAAVTAFWGKVKVDEVGGEALGRL</td>\n",
       "      <td>3447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>PPCRGIFCRRVGSSSAIARPGKTLSTFITV</td>\n",
       "      <td>3448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>SFLNFFKGAAKNLLAAGLDKLKCKISGTQC</td>\n",
       "      <td>3449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>VTLASHLPSDFTPAVHASLDKFLANVSTVL</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3451 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Sequence    Id\n",
       "0                         AAGMGFFGAR     0\n",
       "1                         AAHCIQLGKR     1\n",
       "2                         AAHCIVLHHN     2\n",
       "3                         AAHCLAIGRK     3\n",
       "4                         AAHCLAIGRR     4\n",
       "...                              ...   ...\n",
       "3446  MLSLIFLHRLKSMRKRLDRKLRLWHRKNYP  3446\n",
       "3447  MLTAEEKAAVTAFWGKVKVDEVGGEALGRL  3447\n",
       "3448  PPCRGIFCRRVGSSSAIARPGKTLSTFITV  3448\n",
       "3449  SFLNFFKGAAKNLLAAGLDKLKCKISGTQC  3449\n",
       "3450  VTLASHLPSDFTPAVHASLDKFLANVSTVL  3450\n",
       "\n",
       "[3451 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Path('../data')\n",
    "Ec = pd.read_csv(data/'Ec.csv')[['sequence']] # only preserve the sequence\n",
    "Ec['Id'] = Ec.index\n",
    "Ec = Ec.rename({'sequence': 'Sequence'}, axis=1)\n",
    "Ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list()\n",
    "Ec = construct_features(Ec)\n",
    "Ec_features = Ec.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Ec_features.pkl', 'wb') as f:\n",
    "    pickle.dump(Ec_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-30 14:40:03.158] Start to evalute the model:\n",
      "[2024-04-30 14:40:03.197] Evaluating cascade layer = 0 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model_Ec \u001b[38;5;241m=\u001b[39m CascadeForestRegressor()\n\u001b[1;32m      4\u001b[0m model_Ec\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/Ec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m y_predict_Ec \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_Ec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEc_features\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AMP/lib/python3.9/site-packages/deepforest/cascade.py:1689\u001b[0m, in \u001b[0;36mCascadeForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28mprint\u001b[39m(msg\u001b[38;5;241m.\u001b[39mformat(_utils\u001b[38;5;241m.\u001b[39mctime(), layer_idx))\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1689\u001b[0m     X_aug_test_ \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1691\u001b[0m     binner_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_binner(layer_idx)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AMP/lib/python3.9/site-packages/deepforest/_layer.py:143\u001b[0m, in \u001b[0;36mBaseCascadeLayer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preserved for the naming consistency.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AMP/lib/python3.9/site-packages/deepforest/_layer.py:159\u001b[0m, in \u001b[0;36mBaseCascadeLayer.predict_full\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    156\u001b[0m         estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mload_estimator(estimator)\n\u001b[1;32m    158\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs \u001b[38;5;241m*\u001b[39m idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs \u001b[38;5;241m*\u001b[39m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 159\u001b[0m     pred[:, left:right] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AMP/lib/python3.9/site-packages/deepforest/_estimator.py:222\u001b[0m, in \u001b[0;36mEstimator.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_classifier:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m--> 222\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pred\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    224\u001b[0m     pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(pred, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AMP/lib/python3.9/site-packages/deepforest/forest.py:788\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    785\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    787\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_partition_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# avoid storing the output of every estimator by summing them here\u001b[39;00m\n\u001b[1;32m    791\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AMP/lib/python3.9/site-packages/deepforest/forest.py:203\u001b[0m, in \u001b[0;36m_partition_estimators\u001b[0;34m(n_estimators, n_jobs)\u001b[0m\n\u001b[1;32m    199\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(effective_n_jobs(n_jobs), n_estimators)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Partition estimators between jobs\u001b[39;00m\n\u001b[1;32m    202\u001b[0m n_estimators_per_job \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\n\u001b[0;32m--> 203\u001b[0m     n_jobs, n_estimators \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_jobs, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m\n\u001b[1;32m    204\u001b[0m )\n\u001b[1;32m    205\u001b[0m n_estimators_per_job[: n_estimators \u001b[38;5;241m%\u001b[39m n_jobs] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    206\u001b[0m starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(n_estimators_per_job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AMP/lib/python3.9/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from deepforest import CascadeForestRegressor\n",
    "\n",
    "model_Ec = CascadeForestRegressor()\n",
    "model_Ec.load(\"model/Ec\")\n",
    "y_predict_Ec = model_Ec.predict(Ec_features).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b38132ae02de92ff4889f7e830da5868bdc7ba55101647ec353528b6f1171a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
