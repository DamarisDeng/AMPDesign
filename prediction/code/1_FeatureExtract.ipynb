{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis as PA\n",
    "from modlamp.descriptors import PeptideDescriptor, GlobalDescriptor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import re, math, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous\n",
    "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "             'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
    "             'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "n_gram statistics\n",
    "\"\"\"\n",
    "\n",
    "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H', \n",
    "            'I', 'K', 'L', 'M', 'N', 'P', 'Q', \n",
    "            'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "def get_aan_corpus(n=2):\n",
    "    '''\n",
    "    Get AA corpus of n_gram (e.g. Di, Tri, etc.)\n",
    "    Output: AA n_gram corpus ((e.g. Di:400, Tri:3000, etc.))\n",
    "    '''\n",
    "    n_corpus = []\n",
    "    if n <= 2:\n",
    "        for i in _AALetter:\n",
    "            for j in _AALetter:\n",
    "               n_corpus.append(\"{}{}\".format(i, j))\n",
    "        return n_corpus\n",
    "    for i in get_aan_corpus(n - 1):\n",
    "        for j in _AALetter:\n",
    "            n_corpus.append(\"{}{}\".format(i, j))\n",
    "    return n_corpus\n",
    "\n",
    "\n",
    "def get_ngram_counts(seq, n=2):\n",
    "    '''\n",
    "    Get n_gram statistics\n",
    "    Input: peptide sequence and n\n",
    "    Ouput: n_gram statistic (dictionary) {A.A Corp: Counts}\n",
    "    '''\n",
    "    # Get the name of ngram feature\n",
    "    if n == 2:\n",
    "        prefix = 'DPC'\n",
    "    elif n == 3:\n",
    "        prefix = 'TPC'\n",
    "    else:\n",
    "        prefix = '{}gram'.format(n)\n",
    "\n",
    "    ngrams = [seq[i: i + n] for i in range(len(seq) - n + 1)]\n",
    "    n_corpus = get_aan_corpus(n)\n",
    "    ngram_stat = {}\n",
    "    for aa_ng in n_corpus:\n",
    "        ngram_stat['{}|{}'.format(prefix, aa_ng)] = ngrams.count(aa_ng) / len(ngrams) * 100\n",
    "    return ngram_stat\n",
    "\n",
    "\n",
    "def minSequenceLength(fastas):\n",
    "    minLen = 10000\n",
    "    for i in fastas:\n",
    "        if minLen > len(i[1]):\n",
    "            minLen = len(i[1])\n",
    "    return minLen\n",
    "\n",
    "\n",
    "def minSequenceLengthWithNormalAA(fastas):\n",
    "    minLen = 10000\n",
    "    for i in fastas:\n",
    "        if minLen > len(re.sub('-', '', i[1])):\n",
    "            minLen = len(re.sub('-', '', i[1]))\n",
    "    return minLen\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    input.fasta:      the input protein sequence file in fasta format.\n",
    "    k_space:          the gap of two amino acids, integer, defaule: 5\n",
    "    output:           the encoding file, default: 'encodings.tsv'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generateGroupPairs(groupKey):\n",
    "    gPair = {}\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPair['CKSAAGP|'+key1+'.'+key2] = 0\n",
    "    return gPair\n",
    "\n",
    "\n",
    "def cksaagp(fastas, gap = 5, **kw):\n",
    "    if gap < 0:\n",
    "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    if minSequenceLength(fastas) < gap+2:\n",
    "        print('Error: all the sequence length should be greater than the (gap value) + 2 = ' + str(gap+2) + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    group = {'aliphatic': 'GAVLMI',\n",
    "             'aromatic': 'FYW',\n",
    "             'postivecharge': 'KRH',\n",
    "             'negativecharge': 'DE',\n",
    "             'uncharge': 'STCPNQ'}\n",
    "\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "\n",
    "    groupKey = group.keys()\n",
    "\n",
    "    index = {}\n",
    "    for key in groupKey:\n",
    "        for aa in group[key]:\n",
    "            index[aa] = key\n",
    "\n",
    "    gPairIndex = []\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPairIndex.append('CKSAAGP|'+key1+'.'+key2)\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for g in range(gap + 1):\n",
    "        for p in gPairIndex:\n",
    "            header.append(p+'.gap'+str(g))\n",
    "    encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        for g in range(gap + 1):\n",
    "            gPair = generateGroupPairs(groupKey)\n",
    "            sum = 0\n",
    "            for p1 in range(len(sequence)):\n",
    "                p2 = p1 + g + 1\n",
    "                if p2 < len(sequence) and sequence[p1] in AA and sequence[p2] in AA:\n",
    "                    gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] = gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] + 1\n",
    "                    sum = sum + 1\n",
    "\n",
    "            if sum == 0:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(0)\n",
    "            else:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(gPair[gp] / sum)\n",
    "\n",
    "        encodings.append(code)\n",
    "\n",
    "    return encodings\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    input.fasta:      the input protein sequence file in fasta format.\n",
    "    lambda:           the lambda value, integer, defaule: 30\n",
    "    output:           the encoding file, default: 'encodings.tsv'\n",
    "\"\"\"\n",
    "\n",
    "def Rvalue(aa1, aa2, AADict, Matrix):\n",
    "    return sum([(Matrix[i][AADict[aa1]] - Matrix[i][AADict[aa2]]) ** 2 for i in range(len(Matrix))]) / len(Matrix)\n",
    "\n",
    "\n",
    "def paac(fastas, lambdaValue=30, w=0.05, **kw):\n",
    "    if minSequenceLengthWithNormalAA(fastas) < lambdaValue + 1:\n",
    "        print('Error: all the sequence length should be larger than the lambdaValue+1: ' + str(lambdaValue + 1) + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    # dataFile = re.sub('codes$', '', os.path.split(os.path.realpath('__file__'))[0]) + r'\\data\\PAAC.txt' if platform.system() == 'Windows' else re.sub('codes$', '', os.path.split(os.path.realpath('__file__'))[0]) + '/data/PAAC.txt'\n",
    "    dataFile = '../data/PAAC.txt'\n",
    "    with open(dataFile) as f:\n",
    "        records = f.readlines()\n",
    "    AA = ''.join(records[0].rstrip().split()[1:])\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    AAProperty = []\n",
    "    AAPropertyNames = []\n",
    "    for i in range(1, len(records)):\n",
    "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
    "        AAProperty.append([float(j) for j in array[1:]])\n",
    "        AAPropertyNames.append(array[0])\n",
    "\n",
    "    AAProperty1 = []\n",
    "    for i in AAProperty:\n",
    "        meanI = sum(i) / 20\n",
    "        fenmu = math.sqrt(sum([(j-meanI)**2 for j in i])/20)\n",
    "        AAProperty1.append([(j-meanI)/fenmu for j in i])\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for aa in AA:\n",
    "        header.append('PAAC|' + aa)\n",
    "    for n in range(1, lambdaValue + 1):\n",
    "        header.append('PAAC|lambda' + str(n))\n",
    "    encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        theta = []\n",
    "        for n in range(1, lambdaValue + 1):\n",
    "            theta.append(\n",
    "                sum([Rvalue(sequence[j], sequence[j + n], AADict, AAProperty1) for j in range(len(sequence) - n)]) / (\n",
    "                len(sequence) - n))\n",
    "        myDict = {}\n",
    "        for aa in AA:\n",
    "            myDict[aa] = sequence.count(aa)\n",
    "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
    "        code = code + [(w * j) / (1 + w * sum(theta)) for j in theta]\n",
    "        encodings.append(code)\n",
    "    return encodings\n",
    "\n",
    "\n",
    "def GAAC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphatic': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharge': 'KRH',\n",
    "\t\t'negativecharge': 'DE',\n",
    "\t\t'uncharge': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#']\n",
    "\tfor key in groupKey:\n",
    "\t\theader.append(\"GAAC|\"+key)\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\t\tcode = [name]\n",
    "\t\tcount = Counter(sequence)\n",
    "\t\tmyDict = {}\n",
    "\t\tfor key in groupKey:\n",
    "\t\t\tfor aa in group[key]:\n",
    "\t\t\t\tmyDict[key] = myDict.get(key, 0) + count[aa]\n",
    "\n",
    "\t\tfor key in groupKey:\n",
    "\t\t\tcode.append(myDict[key]/len(sequence))\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "\n",
    "def GDPC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphaticr': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharger': 'KRH',\n",
    "\t\t'negativecharger': 'DE',\n",
    "\t\t'uncharger': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\tbaseNum = len(groupKey)\n",
    "\tdipeptide = [g1+'.'+g2 for g1 in groupKey for g2 in groupKey]\n",
    "\n",
    "\tindex = {}\n",
    "\tfor key in groupKey:\n",
    "\t\tfor aa in group[key]:\n",
    "\t\t\tindex[aa] = key\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#'] + ['GDPC|'+dipname for dipname in dipeptide]\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\n",
    "\t\tcode = [name]\n",
    "\t\tmyDict = {}\n",
    "\t\tfor t in dipeptide:\n",
    "\t\t\tmyDict[t] = 0\n",
    "\n",
    "\t\tsum = 0\n",
    "\t\tfor j in range(len(sequence) - 2 + 1):\n",
    "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]] + 1\n",
    "\t\t\tsum = sum +1\n",
    "\n",
    "\t\tif sum == 0:\n",
    "\t\t\tfor t in dipeptide:\n",
    "\t\t\t\tcode.append(0)\n",
    "\t\telse:\n",
    "\t\t\tfor t in dipeptide:\n",
    "\t\t\t\tcode.append(myDict[t]/sum)\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "\n",
    "def GTPC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphaticr': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharger': 'KRH',\n",
    "\t\t'negativecharger': 'DE',\n",
    "\t\t'uncharger': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\tbaseNum = len(groupKey)\n",
    "\ttriple = [g1+'.'+g2+'.'+g3 for g1 in groupKey for g2 in groupKey for g3 in groupKey]\n",
    "\n",
    "\tindex = {}\n",
    "\tfor key in groupKey:\n",
    "\t\tfor aa in group[key]:\n",
    "\t\t\tindex[aa] = key\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#'] + ['GTPC|'+tname for tname in triple]\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\n",
    "\t\tcode = [name]\n",
    "\t\tmyDict = {}\n",
    "\t\tfor t in triple:\n",
    "\t\t\tmyDict[t] = 0\n",
    "\n",
    "\t\tsum = 0\n",
    "\t\tfor j in range(len(sequence) - 3 + 1):\n",
    "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] + 1\n",
    "\t\t\tsum = sum +1\n",
    "\n",
    "\t\tif sum == 0:\n",
    "\t\t\tfor t in triple:\n",
    "\t\t\t\tcode.append(0)\n",
    "\t\telse:\n",
    "\t\t\tfor t in triple:\n",
    "\t\t\t\tcode.append(myDict[t]/sum)\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "'''\n",
    "Insert Iso_electric Point and net_charge(neutral) feature to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., iep, net_charge}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_phycs(seq_df):\n",
    "    global feature_list\n",
    "    seq_df = seq_df.copy()\n",
    "    #  Function for compute Isoelectric Point or net_charge of peptide\n",
    "    def get_ieq_nc(seq, is_iep=True):\n",
    "        protparam = PA(seq)\n",
    "        return protparam.isoelectric_point() if is_iep else protparam.charge_at_pH(7.0)\n",
    "\n",
    "    # Calculating IsoElectricPoints and NeutralCharge\n",
    "    data_size = seq_df.size\n",
    "    seq_df['PHYC|IEP'] = list(map(get_ieq_nc, seq_df['Sequence'], [True] * data_size))  # IsoElectricPoints\n",
    "    seq_df['PHYC|Net Charge'] = list(map(get_ieq_nc, seq_df['Sequence'], [False] * data_size))  # Charge(Neutral)\n",
    "\n",
    "    # Calculating hydrophobic moment (My assume all peptides are alpha-helix)\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'eisenberg')\n",
    "    descrpt.calculate_moment(window=1000, angle=100, modality='max')\n",
    "    seq_df['PHYC|Hydrophobic Moment'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating \"Hopp-Woods\" hydrophobicity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'hopp-woods')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Hydrophobicity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Energy of Transmembrane Propensity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'tm_tend')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Transmembrane Propensity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Aromaticity\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.aromaticity()\n",
    "    seq_df['PHYC|Aromacity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Levitt_alpha_helical Propensity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'levitt_alpha')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Alpha Helical Propensity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Aliphatic Index\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.aliphatic_index()\n",
    "    seq_df['PHYC|Aliphatic Index'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Boman Index\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.boman_index()\n",
    "    seq_df['PHYC|Boman Index'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    feature_list.append('PHYCS')\n",
    "\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "'''\n",
    "Insert Amino acid composition to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., AAC_Ax ... AAC_Yx}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_aac(seq_df):\n",
    "    global feature_list # changed\n",
    "    seq_df = seq_df.copy()\n",
    "    # Compute AAC for peptide in specific A.A\n",
    "    def get_aac(seq, aa):\n",
    "        return seq.count(aa) / len(seq) * 100\n",
    "\n",
    "    # processing data_frame\n",
    "    data_size = seq_df.size\n",
    "    for ll in _AALetter:\n",
    "        seq_df['AAC_{}'.format(ll)] = list(map(get_aac, seq_df['Sequence'], [ll] * data_size))\n",
    "    feature_list.append('AAC')\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "'''\n",
    "Insert n_grams Descriptor to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., ngram_(1), .., ngram(20 ** n)}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_ngrams(seq_df, n=2):\n",
    "    global feature_list # changed\n",
    "    seq_df = seq_df.copy()\n",
    "    data_size = seq_df.size\n",
    "\n",
    "    ngrams_df = list(map(get_ngram_counts, seq_df['Sequence'], [n] * data_size))\n",
    "    ngrams_df = pd.DataFrame(ngrams_df)  # Convert ngrams features to pd.DataFrame\n",
    "    seq_df = pd.concat([seq_df, ngrams_df], axis=1)\n",
    "    feature_list.append('DPC')\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert CKSAAGP Descriptor to the sequence data_frame\n",
    "(Composition of k-spaced amino acid pairs)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_cksaagp(seq_df, gap=2):\n",
    "    global feature_list # changed\n",
    "    seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    encoding = cksaagp(fastas, gap=gap)\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    feature_list.append('CKSAAGP')\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert PAAC Descriptor to the sequence data_frame\n",
    "(Pseudo Amino Acid Composition)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_paac(seq_df, lamb=3, w=0.1):\n",
    "    global feature_list # changed\n",
    "    seq_df = seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    feature_list.append('PAAC')\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert Grouped n-gram Descriptor to the sequence data_frame\n",
    "(Pseudo Amino Acid Composition)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_gngram(seq_df, n=1): # \n",
    "    seq_df = seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    # encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
    "    if n == 1:\n",
    "        encoding = GAAC(fastas)\n",
    "    elif n == 2:\n",
    "        encoding = GDPC(fastas)\n",
    "    elif n == 3:\n",
    "        encoding = GTPC(fastas)\n",
    "    else:\n",
    "        raise Warning(\"Invalid n-grams, no features added\")\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    return seq_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run extraction on sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAGMGFFGAR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAHCIQLGKR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAHCIVLHHN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAHCLAIGRK</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAHCLAIGRR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>MLSLIFLHRLKSMRKRLDRKLRLWHRKNYP</td>\n",
       "      <td>3446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>MLTAEEKAAVTAFWGKVKVDEVGGEALGRL</td>\n",
       "      <td>3447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>PPCRGIFCRRVGSSSAIARPGKTLSTFITV</td>\n",
       "      <td>3448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>SFLNFFKGAAKNLLAAGLDKLKCKISGTQC</td>\n",
       "      <td>3449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>VTLASHLPSDFTPAVHASLDKFLANVSTVL</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3451 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Sequence    Id\n",
       "0                         AAGMGFFGAR     0\n",
       "1                         AAHCIQLGKR     1\n",
       "2                         AAHCIVLHHN     2\n",
       "3                         AAHCLAIGRK     3\n",
       "4                         AAHCLAIGRR     4\n",
       "...                              ...   ...\n",
       "3446  MLSLIFLHRLKSMRKRLDRKLRLWHRKNYP  3446\n",
       "3447  MLTAEEKAAVTAFWGKVKVDEVGGEALGRL  3447\n",
       "3448  PPCRGIFCRRVGSSSAIARPGKTLSTFITV  3448\n",
       "3449  SFLNFFKGAAKNLLAAGLDKLKCKISGTQC  3449\n",
       "3450  VTLASHLPSDFTPAVHASLDKFLANVSTVL  3450\n",
       "\n",
       "[3451 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Path('../data')\n",
    "Ec = pd.read_csv(data/'Ec.csv')[['sequence']] # only preserve the sequence\n",
    "Ec['Id'] = Ec.index\n",
    "Ec = Ec.rename({'sequence': 'Sequence'}, axis=1)\n",
    "Ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list()\n",
    "Ec = construct_features(Ec)\n",
    "Ec_features = Ec.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = '../data/Ec_features.pkl'\n",
    "with open(features_path, 'wb') as f:\n",
    "    pickle.dump(Ec_features, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-30 07:16:12.419] Start to evalute the model:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The binner was fitted with 553 features but 555 features got passed to `transform`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model_Ec \u001b[38;5;241m=\u001b[39m CascadeForestRegressor()\n\u001b[1;32m     12\u001b[0m model_Ec\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/Ec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m y_predict_Ec \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_Ec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEc_features\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/miniconda3/envs/DF/lib/python3.9/site-packages/deepforest/cascade.py:1678\u001b[0m, in \u001b[0;36mCascadeForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Start to evalute the model:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(_utils\u001b[38;5;241m.\u001b[39mctime()))\n\u001b[1;32m   1677\u001b[0m binner_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_binner(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 1678\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinner_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1679\u001b[0m X_middle_test_ \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39minit_array(X_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_aug_features_)\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_):\n",
      "File \u001b[0;32m~/miniconda3/envs/DF/lib/python3.9/site-packages/deepforest/cascade.py:696\u001b[0m, in \u001b[0;36mBaseCascadeForest._bin_data\u001b[0;34m(self, binner, X, is_training_data)\u001b[0m\n\u001b[1;32m    694\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m binner\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m \u001b[43mbinner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(X_binned)\n\u001b[1;32m    698\u001b[0m toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/DF/lib/python3.9/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/DF/lib/python3.9/site-packages/deepforest/_binner.py:161\u001b[0m, in \u001b[0;36mBinner.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bins_non_missing_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    157\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe binner was fitted with \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m features but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m features got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m passed to `transform`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    162\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bins_non_missing_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, dtype\u001b[38;5;241m=\u001b[39mX_DTYPE, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m X_binned \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(X, dtype\u001b[38;5;241m=\u001b[39mX_BINNED_DTYPE, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The binner was fitted with 553 features but 555 features got passed to `transform`."
     ]
    }
   ],
   "source": [
    "from deepforest import CascadeForestRegressor\n",
    "# import pandas\n",
    "import pickle\n",
    "\n",
    "#load features\n",
    "features_path = '../data/Ec_features.pkl'\n",
    "file = open(features_path, 'rb')\n",
    "Ec_features = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "model_Ec = CascadeForestRegressor()\n",
    "model_Ec.load(\"../model/Ec\")\n",
    "y_predict_Ec = model_Ec.predict(Ec_features).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_Ec.to_csv('../data/predictResult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b38132ae02de92ff4889f7e830da5868bdc7ba55101647ec353528b6f1171a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
